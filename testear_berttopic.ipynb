{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154eeb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import pymysql\n",
    "import os \n",
    "from bertopic import BERTopic\n",
    "import nbformat\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import datamapplot as dmp\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import google.generativeai as genai\n",
    "\n",
    "print(nbformat.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26991b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv(override=True)\n",
    "# Conectar a MySQL\n",
    "conn = pymysql.connect(\n",
    "    host=os.getenv('HOST'),\n",
    "    user=os.getenv('USER2'),\n",
    "    password=os.getenv('PASSWORD'),\n",
    "    database=os.getenv('DATABASE')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98de0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultar registros nuevos o actualizados\n",
    "n = 200000\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(f\"SELECT id, titulo, contenido_limpio, fecha, url, created_at, medio FROM noticias limit {n};\")\n",
    "\n",
    "# Indexar los registros en Elasticsearch\n",
    "# Esto borra cualquier campo que exista para un documento\n",
    "i = 0\n",
    "docs = []\n",
    "for row in cursor.fetchall():\n",
    "    print(row[0], row[1]),\n",
    "    if row[1] is not None:\n",
    "        docs.append(row[1])\n",
    "    i += 1\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9252f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Guardar en un archivo parquet\n",
    "df = pd.DataFrame({\"text\": docs})\n",
    "df.to_parquet('data/titulos.parquet', index=False)\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f98f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "genai.configure(api_key=os.getenv('API_KEY'))\n",
    "model = genai.GenerativeModel('gemini-2.5-flash-lite')\n",
    "\n",
    "# Configuración de generación\n",
    "generation_config = genai.types.GenerationConfig(\n",
    "    max_output_tokens=50,\n",
    "    temperature=0.7,\n",
    "    candidate_count=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33276495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "\n",
    "\n",
    "# Step 1 - Extract embeddings\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Step 2 - Reduce dimensionality\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine')\n",
    "\n",
    "# Step 3 - Cluster reduced embeddings\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=35, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "\n",
    "# Step 4 - Tokenize topics\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Step 5 - Create topic representation\n",
    "ctfidf_model = ClassTfidfTransformer()\n",
    "\n",
    "# Step 6 - (Optional) Fine-tune topic representations with\n",
    "# a `bertopic.representation` model\n",
    "representation_model = KeyBERTInspired()\n",
    "\n",
    "# All steps together\n",
    "topic_model = BERTopic(\n",
    "  embedding_model=embedding_model,          # Step 1 - Extract embeddings\n",
    "  umap_model=umap_model,                    # Step 2 - Reduce dimensionality\n",
    "  hdbscan_model=hdbscan_model,              # Step 3 - Cluster reduced embeddings\n",
    "  vectorizer_model=vectorizer_model,        # Step 4 - Tokenize topics\n",
    "  ctfidf_model=ctfidf_model,                # Step 5 - Extract topic words\n",
    "  representation_model=representation_model # Step 6 - (Optional) Fine-tune topic representations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b5bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correr el modelo\n",
    "topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1070f0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar topicos y probabilidades\n",
    "with open('data/bertopic_results.pkl', 'wb') as f:\n",
    "    pickle.dump({'topics': topics, 'probs': probs}, f)\n",
    "\n",
    "# Guardar modelo completo\n",
    "with open('data/bertopic_model.pkl', 'wb') as f:\n",
    "    pickle.dump(topic_model, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b052bd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explorar lo que salió\n",
    "x = topic_model.get_topic_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dec6781",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()[\"Representation\"][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014f85a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_topicos = topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9d7c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "waiting_time = 60\n",
    "max_attempts = 5\n",
    "\n",
    "topic_titles  = []\n",
    "# 2. Obtener información de los tópicos\n",
    "info_topicos = topic_model.get_topic_info()\n",
    "total_topics = info_topicos.shape[0]\n",
    "\n",
    "titulos = {}\n",
    "\n",
    "for index, row in info_topicos.iterrows():\n",
    "    topic_id = row['Topic']\n",
    "\n",
    "    if topic_id == -1:\n",
    "        topic_titles.append(\"cluster outlier\")\n",
    "        continue\n",
    "\n",
    "    palabras_topico = topic_model.get_topic(topic_id)\n",
    "    palabras_principales = [palabra for palabra, peso in palabras_topico[:5]]\n",
    "    # Obtener documentos representativos del tópico\n",
    "    docs_representativos = row['Representative_Docs']\n",
    "    # Tomar los primeros 2 documentos representativos como contexto\n",
    "    contexto_docs = \". \".join(docs_representativos)\n",
    "    # Crear prompt más informativo con palabras clave y documentos representativos\n",
    "    palabras_texto = \", \".join(palabras_principales)\n",
    "    print(\"Tópico \", index, \"de \", total_topics )\n",
    "    prompt = f\"Estoy tratando de ponerle nombre a clusters que provienen de bertopic. Basándote en estas palabras clave: {palabras_texto} y estos ejemplos: {contexto_docs}. Crea un solo título descriptivo corto para mi cluster. No agregues ningún comentario. Quiero solo el título\"\n",
    "\n",
    "    # Se intenta varias veces antes de dar el caso por perdido\n",
    "    attempts = 0\n",
    "    while attempts < max_attempts:\n",
    "        try:\n",
    "            response = model.generate_content(prompt, generation_config=generation_config)\n",
    "            topic_titles.append(response.text.strip())\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error al generar título para el tópico {topic_id}: {e}\")\n",
    "            attempts += 1\n",
    "            if attempts == max_attempts:\n",
    "                topic_titles.append(\"⚠️ Error al generar título después de {} intentos\".format(max_attempts))\n",
    "    \n",
    "    if index % 10 == 0:\n",
    "        print(f\"Durmiendo por {waiting_time} segundos\")\n",
    "        time.sleep(waiting_time)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e29b3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarda la lista en un archivo\n",
    "with open(\"data/topic_titles.pkl\", \"wb\") as f:\n",
    "    pickle.dump(topic_titles, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca0c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_representativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ba3a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971f0010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actualizar el título de los tópicos por el conseguido con el modelo de google\n",
    "\n",
    "#  Obtener la información de los documentos\n",
    "docs_info = topic_model.get_document_info(docs)\n",
    "\n",
    "# Crear un diccionario a partir de la lista\n",
    "topic_id_to_title =  {i:topic_titles[i + 1 ]  for i in range(-1, len(topic_titles) - 1)    }\n",
    "\n",
    "#docs_info.head()\n",
    "docs_info[\"Topic_Title\"] = docs_info[\"Topic\"].map(topic_id_to_title)\n",
    "\n",
    "\n",
    "docs_info.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12509525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Obtén los embeddings de los documentos\n",
    "embeddings = topic_model._extract_embeddings(docs, method=\"document\")\n",
    "\n",
    "# Reduce dimensionalidad a 2D\n",
    "umap_model = UMAP(n_components=2, random_state=42)\n",
    "embeddings_2d = umap_model.fit_transform(embeddings)\n",
    "\n",
    "# Obtén los clusters (topics)\n",
    "topic_labels = np.array(topics)\n",
    "\n",
    "\n",
    "# Guarda la lista en un archivo\n",
    "with open(\"data/embeddings_2d.pkl\", \"wb\") as f:\n",
    "    pickle.dump(embeddings_2d, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bbcde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filtra los outliers (topic -1)\n",
    "mask = topic_labels != -1\n",
    "embeddings_2d_filtered = embeddings_2d[mask]\n",
    "topic_labels_filtered = topic_labels[mask]\n",
    "custom_labels_filtered = docs_info[\"Topic_Title\"][mask]\n",
    "titles_filtered = np.array(docs)[mask]  # docs debe ser la lista de títulos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b6ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = px.scatter(\n",
    "    x=embeddings_2d_filtered[:, 0],\n",
    "    y=embeddings_2d_filtered[:, 1],\n",
    "    color=custom_labels_filtered.astype(str),\n",
    "    hover_name=titles_filtered,\n",
    "    hover_data={\"Tópico\": custom_labels_filtered},\n",
    "    labels={'color': 'Topic'},\n",
    "    title=\"Clusters de noticias por BERTopic (sin outliers)\"\n",
    ")\n",
    "fig.update_traces(marker=dict(size=8))\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a279324",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Acomodar los nombres de los clusters para el paquete de visualización\n",
    "arr_str = custom_labels_filtered.astype(str)\n",
    "\n",
    "# Armar la leyenda que aparece en el hover\n",
    "combined_hover_text = [f\"NOTICIA: {title}\\nCLUSTER {text}\" for title, text in zip(titles_filtered, arr_str)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268ddcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Visualización\n",
    "plot = dmp.create_interactive_plot(\n",
    "    embeddings_2d_filtered,\n",
    "    arr_str,\n",
    "    hover_text=combined_hover_text\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "plot.save(\"topicos_noticias_dev.html\")\n",
    "\n",
    "plot\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
